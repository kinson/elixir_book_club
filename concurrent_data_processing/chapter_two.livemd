# Chapter Two

## Starting With a Basic GenServer

```elixir
defmodule SendServer do
  use GenServer
end
```

### `use GenServer`

* automatically injects the line `@behavior GenServer`
* provides a default `GenServer` implementation by injecting all functions required by the `GenServer` behaviour

## GenServer Callbacks in Depth

```elixir
defmodule SendServer do
  use GenServer

  def init(args) do
    IO.puts("Received Args #{inspect(args)}")
    max_retries = Keyword.get(args, :max_retries, 5)
    state = %{emails: [], max_retries: max_retries}
    {:ok, state}
  end
end
```

```elixir
# try it out
{:ok, pid} = GenServer.start(SendServer, max_retries: 1)

GenServer.stop(pid)
```

* other options for returning in `init`

<!-- livebook:{"force_markdown":true} -->

```elixir
{:ok, state}
{:ok, state, {:continue, term}}
:ignore
{:stop, reason}
```

* `{:continue, term}` is a good way to do initialization logic without blocking the response
  * `{:ok, state, {:continue, :fetch_from_db}}` will call `handle_continue` callback with `:fetch_from_db`
* `{:stop, reason}` will stop the process from continuing, if under a supervisor, it will be restarted
* `:ignore` is same as above but it will not be restarted if under a supervisor

#### `handle_continue`

Acceptable Return Values:

* `{:noreply, new_state}`
* `{:noreply, new_state, {:continue, term}}`
* `{:stop, reason, new_state}`

```elixir
defmodule SendServer do
  use GenServer

  def init(args) do
    IO.puts("Received Args #{inspect(args)}")
    max_retries = Keyword.get(args, :max_retries, 5)
    state = %{emails: [], max_retries: max_retries}
    {:ok, state}
  end

  def handle_call(:get_state, _from, state) do
    {:reply, state, state}
  end
end
```

```elixir
{:ok, pid} = GenServer.start(SendServer, max_retries: 1)

GenServer.call(pid, :get_state)
```

Now implement sending emails with handle cast!

```elixir
defmodule Sender do
  def emails() do
    ["emailone@gmail.com", "email2@gmail.com", "email3@gmail.com"]
  end

  def send_email(email) do
    Process.sleep(1_000)
    IO.puts("Email to #{email} sent")
    {:ok, "email_sent"}
  end

  def notify_all(emails) do
    emails
    |> Task.async_stream(&send_email/1)
    |> Enum.to_list()
  end
end

defmodule SendServer do
  use GenServer

  def init(args) do
    IO.puts("Received Args #{inspect(args)}")
    max_retries = Keyword.get(args, :max_retries, 5)
    state = %{emails: [], max_retries: max_retries}
    {:ok, state}
  end

  def handle_call(:get_state, _from, state) do
    {:reply, state, state}
  end

  def handle_cast({:send, email}, state) do
    Sender.send_email(email)
    emails = [%{email: email, status: "send", retries: 0}] ++ state.emails

    {:noreply, %{state | emails: emails}}
  end
end
```

```elixir
# try out sending emails with GenServer
{:ok, pid} = GenServer.start(SendServer, max_retries: 1)

GenServer.cast(pid, {:send, "hello@gmail.com"})
```

```elixir
defmodule Sender do
  def emails() do
    ["emailone@gmail.com", "email2@gmail.com", "email3@gmail.com"]
  end

  def send_email("bademail@gmail.com"), do: :error

  def send_email(email) do
    Process.sleep(1_000)
    IO.puts("Email to #{email} sent")
    {:ok, "email_sent"}
  end

  def notify_all(emails) do
    emails
    |> Task.async_stream(&send_email/1)
    |> Enum.to_list()
  end
end

defmodule SendServer do
  use GenServer

  def init(args) do
    IO.puts("Received Args #{inspect(args)}")
    max_retries = Keyword.get(args, :max_retries, 5)
    state = %{emails: [], max_retries: max_retries}

    Process.send_after(self(), :retry, 5000)
    {:ok, state}
  end

  def handle_call(:get_state, _from, state) do
    {:reply, state, state}
  end

  def handle_cast({:send, email}, state) do
    status =
      case Sender.send_email(email) do
        {:ok, "email_sent"} -> "sent"
        :error -> "failed"
      end

    emails = [%{email: email, status: status, retries: 0}] ++ state.emails

    {:noreply, %{state | emails: emails}}
  end

  def handle_info(:retry, state) do
    {failed, done} =
      Enum.split_with(state.emails, fn item ->
        item.status == "failed" && item.retries < state.max_retries
      end)

    retried =
      Enum.map(failed, fn item ->
        IO.puts("retrying email #{item.email}...")

        new_status =
          case Sender.send_email(item.email) do
            {:ok, "email_sent"} -> "sent"
            :error -> "failed"
          end

        %{email: item.email, status: new_status, retries: item.retries + 1}
      end)

    Process.send_after(self(), :retry, 5000)

    {:noreply, %{state | emails: retried ++ done}}
  end
end
```

```elixir
{:ok, pid} = GenServer.start(SendServer, max_retries: 1)

GenServer.cast(pid, {:send, "hello@world.com"})

GenServer.cast(pid, {:send, "bademail@gmail.com"})
```

### Process Teardown

* `terminate/2` is a callback usually invoked before the process exists, but only when the process *itself* is responsible for the exit
  * Most of the time this is the result of ending callback with `{:stop...}` (excluding `init/1`) or when an unhandled exception happens in the process
  * Not invoked when external events cause the process to close (e.g. when the whole application stops)
  * If you want to ensure that `terminate/2` is always called, use `Process.flag(:trap_exit, true)` on the process, or use `Process.monitor` to perform the work in a separate process

```elixir
defmodule Sender do
  def send_email("bademail@gmail.com"), do: :error

  def send_email(email) do
    Process.sleep(1_000)
    IO.puts("Email to #{email} sent")
    {:ok, "email_sent"}
  end
end

defmodule SendServer do
  use GenServer

  def init(args) do
    IO.puts("Received Args #{inspect(args)}")
    max_retries = Keyword.get(args, :max_retries, 5)
    state = %{emails: [], max_retries: max_retries}

    Process.send_after(self(), :retry, 5000)
    {:ok, state}
  end

  def handle_call(:get_state, _from, state) do
    {:reply, state, state}
  end

  def handle_cast({:send, email}, state) do
    status =
      case Sender.send_email(email) do
        {:ok, "email_sent"} -> "sent"
        :error -> "failed"
      end

    emails = [%{email: email, status: status, retries: 0}] ++ state.emails

    {:noreply, %{state | emails: emails}}
  end

  def handle_info(:retry, state) do
    {failed, done} =
      Enum.split_with(state.emails, fn item ->
        item.status == "failed" && item.retries < state.max_retries
      end)

    retried =
      Enum.map(failed, fn item ->
        IO.puts("retrying email #{item.email}...")

        new_status =
          case Sender.send_email(item.email) do
            {:ok, "email_sent"} -> "sent"
            :error -> "failed"
          end

        %{email: item.email, status: new_status, retries: item.retries + 1}
      end)

    Process.send_after(self(), :retry, 5000)

    {:noreply, %{state | emails: retried ++ done}}
  end

  def terminate(reason, _state) do
    IO.puts("terminating with reason #{reason}")
    # return value is not important
  end
end
```

```elixir
{:ok, pid} = GenServer.start(SendServer, max_retries: 1)

GenServer.stop(pid)
```

### Process Blocking

* although `handle_cast` will return `:ok` right away, the process still pauses for 3 seconds to send the email
* all of these messages will be put in the processes message queue and execute one-by-one
* By default, `GenServer.call` will error after 5 seconds

#### Taks Module with GenServer

* Free up GenServer process by using `Task.start/1` and `Task.async/2` to run code concurrently
* When they are done, they will send messages back to `GenServer` which can be handled by `handle_info/2`
* See `Task.Supervisor.async_nolink/3` for more examples

## Building a Job-Processing System

```elixir
defmodule Jobber.Job do
  use GenServer

  defstruct [:work, :id, :max_retries, retries: 0, status: "new"]

  def init(args) do
    work = Keyword.fetch!(args, :work)
    id = Keyword.get(args, :id, random_job_id())

    max_retries = Keyword.get(args, :max_retries, 3)

    state = %Jobber.Job{id: id, work: work, max_retries: max_retries}

    {:ok, state, {:continue, :run}}
  end

  def handle_continue(:run, state) do
    new_state = state.work.() |> handle_job_result(state)

    if new_state.status == "errored" do
      Process.send_after(self(), :retry, 5000)
      {:noreply, new_state}
    else
      IO.puts("Job exiting #{state.id}")
      {:stop, :normal, new_state}
    end
  end

  def handle_info(:retry, state) do
    {:noreply, state, {:continue, :run}}
  end

  defp handle_job_result({:ok, _data}, state) do
    IO.puts("Job completed #{state.id}")
    %Jobber.Job{state | status: "done"}
  end

  defp handle_job_result(:error, %{status: "new"} = state) do
    IO.puts("Job errored #{state.id}")
    %Jobber.Job{state | status: "errored"}
  end

  defp handle_job_result(:error, %{status: "errored"} = state) do
    IO.puts("Job retry failed #{state.id}")

    new_state = %Jobber.Job{state | retries: state.retries + 1}

    if new_state.retries == state.max_retries do
      %Jobber.Job{new_state | status: "failed"}
    else
      new_state
    end
  end

  defp random_job_id do
    :crypto.strong_rand_bytes(5)
    |> Base.url_encode64(padding: false)
  end
end
```

```elixir
GenServer.start(Jobber.Job,
  work: fn ->
    Process.sleep(500)
    {:ok, []}
  end
)
```

```elixir
GenServer.start(Jobber.Job,
  work: fn ->
    Process.sleep(500)
    :error
  end
)
```

## Introducing DynamicSupervisor

```elixir
defmodule Application do
  def start(_type, _args) do
    children = [{DynamicSupervisor, strategy: :one_for_one, name: Jobber.JobRunner}]
    opts = [strategy: :one_for_one, name: Jobber.Supervisor]

    Supervisor.start_link(children, opts)
  end
end
```

* `strategy` setting isi required and `:one_for_one` is the only one accepted right now

```elixir
good_job = fn ->
  Process.sleep(1200)
  {:ok, []}
end

bad_job = fn ->
  Process.sleep(1300)
  :error
end
```

```elixir
defmodule Jobber do
  alias Jobber.{JobRunner, Job}

  def start_job(args) do
    DynamicSupervisor.start_child(JobRunner, {Job, args})
  end
end
```

```elixir
# fails without start_link defined in `Job`
Jobber.start_job(work: good_job)
```

```elixir
defmodule Jobber.Job do
  use GenServer

  defstruct [:work, :id, :max_retries, retries: 0, status: "new"]

  def start_link(args) do
    GenServer.start_link(__MODULE__, args)
  end

  def init(args) do
    work = Keyword.fetch!(args, :work)
    id = Keyword.get(args, :id, random_job_id())

    max_retries = Keyword.get(args, :max_retries, 3)

    state = %Jobber.Job{id: id, work: work, max_retries: max_retries}

    {:ok, state, {:continue, :run}}
  end

  def handle_continue(:run, state) do
    new_state = state.work.() |> handle_job_result(state)

    if new_state.status == "errored" do
      Process.send_after(self(), :retry, 5000)
      {:noreply, new_state}
    else
      IO.puts("Job exiting #{state.id}")
      {:stop, :normal, new_state}
    end
  end

  def handle_info(:retry, state) do
    {:noreply, state, {:continue, :run}}
  end

  defp handle_job_result({:ok, _data}, state) do
    IO.puts("Job completed #{state.id}")
    %Jobber.Job{state | status: "done"}
  end

  defp handle_job_result(:error, %{status: "new"} = state) do
    IO.puts("Job errored #{state.id}")
    %Jobber.Job{state | status: "errored"}
  end

  defp handle_job_result(:error, %{status: "errored"} = state) do
    IO.puts("Job retry failed #{state.id}")

    new_state = %Jobber.Job{state | retries: state.retries + 1}

    if new_state.retries == state.max_retries do
      %Jobber.Job{new_state | status: "failed"}
    else
      new_state
    end
  end

  defp random_job_id do
    :crypto.strong_rand_bytes(5)
    |> Base.url_encode64(padding: false)
  end
end
```

```elixir
Application.start([], [])
Jobber.start_job(work: good_job)
```

### Fixing Infinite Jobs on Exit

* Update `strategy` to `:transient` so processes exiting normally are not restarted

```elixir
defmodule Jobber.Job do
  use GenServer, restart: :transient

  defstruct [:work, :id, :max_retries, retries: 0, status: "new"]

  def start_link(args) do
    GenServer.start_link(__MODULE__, args)
  end

  def init(args) do
    work = Keyword.fetch!(args, :work)
    id = Keyword.get(args, :id, random_job_id())

    max_retries = Keyword.get(args, :max_retries, 3)

    state = %Jobber.Job{id: id, work: work, max_retries: max_retries}

    {:ok, state, {:continue, :run}}
  end

  def handle_continue(:run, state) do
    new_state = state.work.() |> handle_job_result(state)

    if new_state.status == "errored" do
      Process.send_after(self(), :retry, 5000)
      {:noreply, new_state}
    else
      IO.puts("Job exiting #{state.id}")
      {:stop, :normal, new_state}
    end
  end

  def handle_info(:retry, state) do
    {:noreply, state, {:continue, :run}}
  end

  defp handle_job_result({:ok, _data}, state) do
    IO.puts("Job completed #{state.id}")
    %Jobber.Job{state | status: "done"}
  end

  defp handle_job_result(:error, %{status: "new"} = state) do
    IO.puts("Job errored #{state.id}")
    %Jobber.Job{state | status: "errored"}
  end

  defp handle_job_result(:error, %{status: "errored"} = state) do
    IO.puts("Job retry failed #{state.id}")

    new_state = %Jobber.Job{state | retries: state.retries + 1}

    if new_state.retries == state.max_retries do
      %Jobber.Job{new_state | status: "failed"}
    else
      new_state
    end
  end

  defp random_job_id do
    :crypto.strong_rand_bytes(5)
    |> Base.url_encode64(padding: false)
  end
end
```

```elixir
# Application.start([], [])
Jobber.start_job(work: good_job)
Jobber.start_job(work: bad_job)
```

```elixir
doomed_job = fn ->
  Process.sleep(5000)
  raise "Boom!"
end
```

```elixir
Application.start([], [])
# this should throw an exception...
Jobber.start_job(work: doomed_job)
```

We can adjust the `max_seconds` before the Supervisor gives up on a process

```elixir
defmodule Application do
  def start(_type, _args) do
    children = [
      {DynamicSupervisor, strategy: :one_for_one, max_seconds: 30, name: Jobber.JobRunner}
    ]

    opts = [strategy: :one_for_one, name: Jobber.Supervisor]

    Supervisor.start_link(children, opts)
  end
end
```

```elixir
Application.start([], [])

Process.whereis(Jobber.JobRunner)

Jobber.start_job(work: doomed_job)

Process.whereis(Job.JobRunner)
```

In this example the supervisor pid is changing because the supervisor itself is crashing and being restarted

This happens because the supervisor cannot keep the process from crashing, so the supervisor itself will exit

As a result, any concurrent Job process will also be terminated. Even if a single process fails to be recovered, it could endanger all other running processes.

This can be fixed by adding a supervisor for each Job process which will handle restarts and gracefully exit when its process fails

## Implementing  a Supervisor

To fix the issue above, we will create a supervisor for each job process with a restart value of `temporary` so it does not cause further damage

```elixir
defmodule Jobber.JobSupervisor do
  use Supervisor, restart: :temporary

  def start_link(args) do
    Supervisor.start_link(__MODULE__, args)
  end

  def init(args) do
    children = [
      {Jobber.Job, args}
    ]

    options = [
      strategy: :one_for_one,
      max_seconds: 30
    ]

    Supervisor.init(children, options)
  end
end
```

```elixir
# use the new supervisor
defmodule Jobber do
  alias Jobber.{JobRunner, JobSupervisor}

  def start_job(args) do
    DynamicSupervisor.start_child(JobRunner, {JobSupervisor, args})
  end
end
```

```elixir
# Test it out! (with supervisor)

IO.puts("Process before boom")
Process.whereis(Jobber.JobRunner) |> IO.inspect()

Jobber.start_job(work: doomed_job)

Process.sleep(2000)

IO.puts("Process after boom")
Process.whereis(Jobber.JobRunner) |> IO.inspect()
```

### Supervisor Strategies

When you define a supervisor, you have several options for the strategy that tell them how to manage child processes:

* `:one_for_one`
  * great when each child process can be restarted independently without impacting sibling processes
* `:one_for_all`
  * will restart all child processes when one of them fails
* `:rest_for_one`
  * similar to `:one_for_all` but only sibling processes started *after* the failed one will be restarted

## Naming Process Using the Registry

### Three types of acceptable names for processes:

* an atom, like `:job_runner` (or Jobber.JobRunner)
* a global `{:global, term}` tuple, which registers the process globally
  * useful for distributed applications
* a `{:via, module, term}` tuple, where `module` is an Elixir module that would take care of the registration process, using the value term

### `Registry`

* each `Registry` works as a process that is in the supervision tree

```elixir
defmodule Application do
  def start(_type, _args) do
    job_runner_config = [
      strategy: :one_for_one,
      max_seconds: 30,
      name: Jobber.JobRunner
    ]

    children = [
      {Registry, keys: :unique, name: Jobber.JobRegistry},
      {DynamicSupervisor, job_runner_config}
    ]

    opts = [strategy: :one_for_one, name: Jobber.Supervisor]

    Supervisor.start_link(children, opts)
  end
end
```

```elixir
defmodule Jobber.Job do
  use GenServer, restart: :transient

  defstruct [:work, :id, :max_retries, retries: 0, status: "new"]

  # DIFFERENT!!
  def start_link(args) do
    args =
      if Keyword.has_key?(args, :id) do
        args
      else
        Keyword.put(args, :id, random_job_id())
      end

    id = Keyword.get(args, :id)
    type = Keyword.get(args, :type)

    GenServer.start_link(__MODULE__, args, name: via(id, type))
  end

  def init(args) do
    work = Keyword.fetch!(args, :work)
    id = Keyword.get(args, :id)

    max_retries = Keyword.get(args, :max_retries, 3)

    state = %Jobber.Job{id: id, work: work, max_retries: max_retries}

    {:ok, state, {:continue, :run}}
  end

  def handle_continue(:run, state) do
    new_state = state.work.() |> handle_job_result(state)

    if new_state.status == "errored" do
      Process.send_after(self(), :retry, 5000)
      {:noreply, new_state}
    else
      IO.puts("Job exiting #{state.id}")
      {:stop, :normal, new_state}
    end
  end

  def handle_info(:retry, state) do
    {:noreply, state, {:continue, :run}}
  end

  defp handle_job_result({:ok, _data}, state) do
    IO.puts("Job completed #{state.id}")
    %Jobber.Job{state | status: "done"}
  end

  defp handle_job_result(:error, %{status: "new"} = state) do
    IO.puts("Job errored #{state.id}")
    %Jobber.Job{state | status: "errored"}
  end

  defp handle_job_result(:error, %{status: "errored"} = state) do
    IO.puts("Job retry failed #{state.id}")

    new_state = %Jobber.Job{state | retries: state.retries + 1}

    if new_state.retries == state.max_retries do
      %Jobber.Job{new_state | status: "failed"}
    else
      new_state
    end
  end

  defp random_job_id do
    :crypto.strong_rand_bytes(5)
    |> Base.url_encode64(padding: false)
  end

  # NEW!!
  defp via(key, value) do
    {:via, Registry, {Jobber.JobRegistry, key, value}}
  end
end
```

### Via Format

<!-- livebook:{"force_markdown":true} -->

```elixir
defp via(key, value) do
  {:via, Registry, {Jobber.JobRegistry, key, value}}
end
```

Must return a tuple `{:via, Registry, config}` where config is also a tuple and either

* `{registry_process, key}` or
* `{registry_process, key, value}`

```elixir
defmodule Jobber do
  alias Jobber.{JobRunner, JobSupervisor}

  def start_job(args) do
    DynamicSupervisor.start_child(JobRunner, {JobSupervisor, args})
  end

  def running_imports() do
    match_all = {:"$1", :"$2", :"$3"}
    guards = [{:==, :"$3", "import"}]
    map_result = [%{id: :"$1", pid: :"$2", type: :"$3"}]

    Registry.select(Jobber.JobRegistry, [{match_all, guards, map_result}])
  end
end
```

#### Registry Select

* takes registry process as first argument followd by a list of match specifications as the last arg
* `match_all` is a wildcard that matches all entries in the registry
* `guards` is a filter that filters results by the third element in the tuple which has to equal "import"
* `map_result` transforms the result by creating a list of maps, assigning each elemt of the tuple to a key, which makes the result more readable

Each value in the Registry is a tuple in the form `{name, pid, value}`

```elixir
defmodule ApplicationWithRegistry do
  def start(_type, _args) do
    job_runner_config = [
      strategy: :one_for_one,
      max_seconds: 30,
      name: Jobber.JobRunner
    ]

    children = [
      {Registry, keys: :unique, name: Jobber.JobRegistry},
      {DynamicSupervisor, job_runner_config}
    ]

    opts = [strategy: :one_for_one, name: Jobber.Supervisor]

    Supervisor.start_link(children, opts)
  end
end

# not working ugh
ApplicationWithRegistry.start([], [])

Process.sleep(1000)

Jobber.start_job(work: good_job, type: "import")
Jobber.start_job(work: good_job, type: "send_email")

Process.sleep(200)

Jobber.running_imports()
```

### Limiting Concurrency of Import Jobs

This is how you do it!

```elixir
defmodule Jobber do
  alias Jobber.{JobRunner, JobSupervisor}

  def start_job(args) do
    if Enum.count(running_imports()) >= 5 do
      {:error, :import_quota_reached}
    else
      DynamicSupervisor.start_child(JobRunner, {JobSupervisor, args})
    end
  end

  def running_imports() do
    match_all = {:"$1", :"$2", :"$3"}
    guards = [{:==, :"$3", "import"}]
    map_result = [%{id: :"$1", pid: :"$2", type: :"$3"}]

    Registry.select(Jobber.JobRegistry, [{match_all, guards, map_result}])
  end
end
```

```elixir
defmodule ApplicationWithRegistry do
  def start(_type, _args) do
    job_runner_config = [
      strategy: :one_for_one,
      max_seconds: 30,
      name: Jobber.JobRunner
    ]

    children = [
      {Registry, keys: :unique, name: Jobber.JobRegistry},
      {DynamicSupervisor, job_runner_config}
    ]

    opts = [strategy: :one_for_one, name: Jobber.Supervisor]

    Supervisor.start_link(children, opts)
  end
end
```

```elixir
Process.sleep(1000)

Jobber.start_job(work: good_job, type: "import")
Jobber.start_job(work: good_job, type: "send_email")

Process.sleep(200)

Jobber.running_imports()
```

## Inspecting Supervisors at Runtime

Two functions that help tell you which processes currently running under a particular supervisor

* `count_children/1` returns map with
  * `:supervisors`, total number of supervisor child process (active & inactive)
  * `:workers` totl number of non-supervisor processes
  * `:specs` total number of all child processe
  * `:active` total active
* `which_children/1` returns a list of child process tuples with:
  * `id` of the process (could be `:undefined`)
  * `pid` of the process (or `:restarting`)
  * `type` either worker or supervisor
  * the module implementation
