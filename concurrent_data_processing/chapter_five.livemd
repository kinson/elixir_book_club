# Chapter 5

## Okay

```elixir
Mix.install([
  {:broadway, "~> 0.6"},
  {:broadway_rabbitmq, "~> 0.6"},
  {:amqp, "~> 1.6"}
])
```

```elixir
defmodule ApplicationBroadway do
  def start(_type, _args) do
    children = [
      BookingsPipeline,
      NotificationsPipeline
    ]

    opts = [strategy: :one_for_one, name: Tickets.Supervisor]

    Supervisor.start_link(children, opts)
  end
end
```

### Introduction to Broadway

* the `GenStage` pipeline generated by Broadway is designed according to current best practices

  * It is fault tolerant and performs graceful shutdowns out of the box

* broadway requires options to start

  * `:name` is used as a prefix when naming processes
  * `:producer` contains config about the source of events
  * `:processors` allows us to configure the stage processes that receive the messages and do most of the work

*

```elixir
defmodule BookingsPipeline do
  use Broadway

  @producer BroadwayRabbitMQ.Producer

  @producer_config [
    queue: "bookings_queue",
    declare: [durable: true],
    on_failure: :reject_and_requeue
  ]

  def start_link(_args) do
    options = [
      name: BookingsPipeline,
      producer: [module: {@producer, @producer_config}],
      processors: [default: []],
      batchers: [cinema: [], musical: [], default: []]
    ]

    Broadway.start_link(__MODULE__, options)
  end

  def handle_message(_processor, message, _context) do
    if Tickets.tickets_available?(message.data.event) do
      case message do
        %{data: %{event: "cinema"}} = message ->
          Broadway.Message.put_batcher(message, :cinema)

        %{data: %{event: "musical"}} = message ->
          Broadway.Message.put_batcher(message, :musical)

        message ->
          message
      end
    else
      Broadway.Message.failed(message, "bookings-closed")
    end
  end

  # def handle_message(_processor, message, _context) do
  #   %{data: %{event: event, user: user}} = message

  #   if Tickets.tickets_available?(event) do
  #     Tickets.create_ticket(user, event)
  #     Tickets.send_email(user)

  #     IO.inspect(message, label: "Message")
  #   else
  #     Broadway.Message.failed(message, "bookings-closed")
  #   end
  # end

  def handle_failed(messages, _context) do
    IO.inspect(messages, label: "Failed messages")

    Enum.map(messages, fn
      %{status: {:failed, "bookings-closed"}} = message ->
        Broadway.Message.configure_ack(message, on_failure: :reject)

      message ->
        message
    end)
  end

  def prepare_messages(messages, _context) do
    messages =
      Enum.map(messages, fn message ->
        Broadway.Message.update_data(message, fn data ->
          [event, user_id] = String.split(data, ", ")
          %{event: event, user_id: user_id}
        end)
      end)

    users = Tickets.users_by_ids(Enum.map(messages, & &1.data.user_id))

    # put users in messages
    Enum.map(messages, fn message ->
      Broadway.Message.update_data(message, fn data ->
        user = Enum.find(users, &(&1.id == data.user_id))
        Map.put(data, :user, user)
      end)
    end)
  end

  def handle_batch(_batcher, messages, batch_info, _context) do
    IO.inspect(batch_info, label: "#{inspect(self())} batch")

    messages
    |> Tickets.insert_all_tickets()
    |> Enum.each(fn message ->
      channel = message.metadata.amqp_channel
      payload = "email,#{message.data.user.email}"
      AMQP.Basic.publish(channel, "", "notifications_queue", payload)
    end)

    messages
  end

  # def handle_batch(_batcher, messages, batch_info, _context) do
  #   IO.inspect(batch_info, label: "#{inspect(self())} batch")
  #   messages
  # end
end
```

```elixir
defmodule Tickets do
  # removed after using AMQP
  # def tickets_available?("cinema") do
  #   Process.sleep(Enum.random(100..200))
  #   false
  # end

  def tickets_available?(_event) do
    Process.sleep(Enum.random(100..200))
    true
  end

  def create_ticket(_user, _event) do
    Process.sleep(Enum.random(250..1000))
  end

  def send_email(_user) do
    Process.sleep(Enum.random(100..250))
  end

  @users [
    %{id: "1", email: "foo@example.com"},
    %{id: "2", email: "bar@example.com"},
    %{id: "3", email: "baz@example.com"}
  ]

  def users_by_ids(ids) when is_list(ids) do
    # normally this would be a db query
    Enum.filter(@users, &(&1.id in ids))
  end

  def insert_all_tickets(messages) do
    # normally ectco insert all
    Process.sleep(Enum.count(messages) * 250)
    messages
  end
end
```

### prepare_messages callback

* lets us do work in bulk when receiving messages
  * e.g. fetch or preload info from the db
  * do it here rather than `handle_message/3`
  * runs before `handle_message/3` and receives a list of messages to iterate over and update with more info

### handle_failed callback

* gives us the ability to check what messages have failed and why and decide if we want to take further action
* can use `configure_ack` to acknowledge failed messages so they are not requeued
  *

## Batching Messages

* batching messages lets you group relevant messages

```elixir
defmodule IEXHelpers do
  def send_messages(num_messages) do
    {:ok, connection} = AMQP.Connection.open()
    {:ok, channel} = AMQP.Channel.open(connection)

    Enum.each(1..num_messages, fn _ ->
      event = Enum.random(["cinema", "musical", "play"])
      user_id = Enum.random(1..3)
      AMQP.Basic.publish(channel, "", "bookings_queue", "#{event},#{user_id}")
    end)

    AMQP.Connection.close(connection)
  end
end
```

#### `handle_batch/4`

* all code within the callback runs concurrently in a separate batch processor
* each "batcher" will start a single batch processor by default which runs the code in `handle_batch/4` to process the given group of mesages

`%BatchInfo{}`

* `batcher` is the batcher group and belongs to one of the groups defined in `starlink/1`

* `:batch_key` is an id for a gorup of messages in the batch

* `:partition` is the partition key if configured

* `:size` is the number of messages in the batch

* by default you get one processeor per batcher, can be increased using the `:concurrency` key on each batcher group

#### Dynamic Batching

* Broadway lets you define batches at runtime with `:batch_key` called *dynamic batching*
* Done by calling `Broadway.Message.put_batch_key/2` in your `handle_message/3` callback

```elixir
defmodule NotificationsPipeline do
  use Broadway

  @producer BroadwayRabbitMQ.Producer

  @producer_config [
    queue: "notifcations_queue",
    declare: [durable: true],
    on_failure: :reject_and_requeue,
    qos: [prefetch_count: 100]
  ]

  def start_link(_args) do
    options = [
      name: NotificationsPipeline,
      producer: [module: {@producer, @producer_config}],
      processors: [default: []],
      batchers: [
        email: [concurrency: 5, batch_timeout: 10_000]
      ]
    ]

    Broadway.start_link(__MODULE__, options)
  end

  def handle_message(message, _context) do
    message
    |> Broadway.Message.put_batcher(:email)
    |> Broadway.Message.put_batch_key(message.data.recipient)
  end

  def prepare_messages(messages, _context) do
    Enum.map(messages, fn message ->
      Broadway.Message.update_data(messages, fn data ->
        [type, recipient] = String.split(data, ",")
        %{type: type, recipient: recipient}
      end)
    end)
  end

  def handle_batch(_batcher, messages, batch_info) do
    IO.puts("#{inspect(self())} Batch #{batch_info}")

    messages
  end
end
```

#### Adjusting Batch Size and Timeout

* `:batch_size` controls the number of messages in a batch
* `:batch_timeout` controls the amount of time the processor waits before sending batch
* ^ work on per-batch key basis

## Wrapping Up

* Broadway simplifies working with message brokers (like rabbitmq) & takes away the complexity of assembling data-processing pipelines

* `Task` module is good for perofrming concurrent work without much hassle

  * Using `Task.aync_stream/3` is a good way to process large collections of data and provide back pressure

* `GenServer` is good for creating processes that maintain their own state and exist for long periods of time

* `GenStage` enables you to create complex data-processing pipelines that are resilent by controlling consumer demand and back-pressure

* `Flow` helps aggregate data by using `GenStage` - good for working with big datasets and doing transformations

* `Broadway` fills a gap when building data ingestion pipelines that consume external events

  * You can use it with message brokers and to build robust event-processing systems
